---

title: Lecture Notes
layout: default
nav_order: 4

---

# Lecture notes
{: .no_toc }


Lecture notes will be posted here throughout the semester.

<br>

## Table of contents
{: .no_toc .text-delta }

1. TOC
{:toc}

<br>


## Topic 1: Geometry and probability in high dimension

***

Theory
{: .label .label-green }

- a first data science example: species delimitation ([html](https://nbviewer.jupyter.org/url/people.math.wisc.edu/~roch/mmids_backup_011024/highdim-intro.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/highdim-intro.ipynb))
- review ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/highdim-review.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/highdim-review.ipynb))
- high-dimensional space ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/highdim-space.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/highdim-space.ipynb))
- clustering: an objective, an algorithm, and a toy example ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/highdim-kmeans.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/highdim-kmeans.ipynb))

Applications
{: .label .label-purple }

- k-means clustering ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/highdim-app.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/highdim-app.ipynb)) [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/sebroc/MMiDS-s20/master?filepath=notebooks/highdim-app.ipynb)
- datasets: [iris-measurements.csv](http://www.math.wisc.edu/~roch/mmids/iris-measurements.csv), [iris-species.csv](http://www.math.wisc.edu/~roch/mmids/iris-species.csv)

<br>

## Topic 2: Orthogonality, QR and least squares

***

Theory
{: .label .label-green }

- motivating example: predicting sales ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/orthog-intro.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/orthog-intro.ipynb))
- review ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/orthog-review.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/orthog-review.ipynb))
- orthogonality ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/orthog-qr.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/orthog-qr.ipynb))
- least squares ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/orthog-ls.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/orthog-ls.ipynb))


Applications
{: .label .label-purple }

- linear regression ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/orthog-app.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/orthog-app.ipynb)) [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/sebroc/MMiDS-s20/master?filepath=notebooks/orthog-app.ipynb)
- datasets: [advertising.csv](http://www.math.wisc.edu/~roch/mmids/advertising.csv), [msn-flight-data-19.csv](http://www.math.wisc.edu/~roch/mmids/msn-flight-data-19.csv)

<br>

## Topic 3: Matrix norms, low-rank approximations, and SVD

***

Theory
{: .label .label-green }

- motivating example: movie recommendations ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/svd-intro.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/svd-intro.ipynb))
- matrix norms and approximating subspaces ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/svd-norms.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/svd-norms.ipynb))
- singular value decomposition ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/svd-def.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/svd-def.ipynb))
- condition numbers ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/svd-condition.ipynb), [ipynb](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/svd-condition.ipynb))


Applications
{: .label .label-purple }

- dimensionality reduction ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/svd-app.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/svd-app.ipynb)) [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/sebroc/MMiDS-s20/master?filepath=notebooks/svd-app.ipynb)
- datasets: [movielens-small-movies.csv](http://www.math.wisc.edu/~roch/mmids/movielens-small-movies.csv), [movielens-small-ratings.csv](http://www.math.wisc.edu/~roch/mmids/movielens-small-ratings.csv), [h3n2-snp.csv](http://www.math.wisc.edu/~roch/mmids/h3n2-snp.csv), [h3n2-other.csv](http://www.math.wisc.edu/~roch/mmids/h3n2-other.csv)

<br>

## Topic 4: Introduction to spectral graph theory

***

Theory
{: .label .label-green }

- motivating example: community detection ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/spectral-intro.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/spectral-intro.ipynb), [slides](http://www.math.wisc.edu/~roch/mmids/spectral-intro.slides.html))
- review: spectral decomposition ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/spectral-review.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/spectral-review.ipynb), [slides](http://www.math.wisc.edu/~roch/mmids/spectral-review.slides.html))
- elements of graph theory ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/spectral-graphs.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/spectral-graphs.ipynb), [slides](http://www.math.wisc.edu/~roch/mmids/spectral-graphs.slides.html))
- laplacian matrix ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/spectral-laplacian.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/spectral-laplacian.ipynb), [slides](http://www.math.wisc.edu/~roch/mmids/spectral-laplacian.slides.html))
- graph partitioning ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/spectral-partitioning.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/spectral-partitioning.ipynb), [slides](http://www.math.wisc.edu/~roch/mmids/spectral-partitioning.slides.html))

Applications
{: .label .label-purple }

- community detection/image segmentation ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/spectral-app.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/spectral-app.ipynb), [slides](http://www.math.wisc.edu/~roch/mmids/spectral-app.slides.html)) [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/sebroc/MMiDS-s20/master?filepath=notebooks/spectral-app.ipynb)
- datasets: [panda.jpg](http://www.math.wisc.edu/~roch/mmids/panda.jpg)


<br>

## Topic 5: Convexity, gradient descent and automatic differentiation

***

Theory
{: .label .label-green }

- motivating example: handwritten digit recognition ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/opt-intro.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/opt-intro.ipynb), [slides](http://www.math.wisc.edu/~roch/mmids/opt-intro.slides.html))
- review: functions of several variables ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/opt-review.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/opt-review.ipynb), [slides](http://www.math.wisc.edu/~roch/mmids/opt-review.slides.html))
- optimality conditions ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/opt-optimality.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/opt-optimality.ipynb), [slides](http://www.math.wisc.edu/~roch/mmids/opt-optimality.slides.html))
- convexity ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/opt-convexity.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/opt-convexity.ipynb), [slides](http://www.math.wisc.edu/~roch/mmids/opt-convexity.slides.html))
- gradient descent ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/opt-gd.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/opt-gd.ipynb), [slides](http://www.math.wisc.edu/~roch/mmids/opt-gd.slides.html))

Applications
{: .label .label-purple }

- logistic regression ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/opt-app1.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/opt-app1.ipynb), [slides](http://www.math.wisc.edu/~roch/mmids/opt-app1.slides.html)) [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/sebroc/MMiDS-s20/master?filepath=notebooks/opt-app1.ipynb)
- deep neural networks ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/opt-app2.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/opt-app2.ipynb), [slides](http://www.math.wisc.edu/~roch/mmids/opt-app2.slides.html)) [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/sebroc/MMiDS-s20/master?filepath=notebooks/opt-app2.ipynb)
- datasets: [lebron.csv](http://www.math.wisc.edu/~roch/mmids/lebron.csv), [advertising.csv](http://www.math.wisc.edu/~roch/mmids/advertising.csv), [SAHeart.csv](http://www.math.wisc.edu/~roch/mmids/SAHeart.csv)

 <br>

## Topic 6: Probabilistic modeling, inference and sampling

***

Theory
{: .label .label-green }

- motivating example ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/prob-intro.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/prob-intro.ipynb), [slides](http://www.math.wisc.edu/~roch/mmids/prob-intro.slides.html))
- review ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/prob-review.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/prob-review.ipynb), [slides](http://www.math.wisc.edu/~roch/mmids/prob-review.slides.html))
- joint distributions: marginalization and conditional independence ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/prob-joint.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/prob-joint.ipynb), [slides](http://www.math.wisc.edu/~roch/mmids/prob-joint.slides.html))
- inference and parameter estimation: variable elimination and expectation-maximization (see Sections 9.2.1-2, 9.3.1-3 , 13.1, 13.2.1-2 in [[Bis](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf)])
- sampling: Markov chain Monte Carlo methods (see Sections 11.2-3 in [[Bis](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf)])

Applications
{: .label .label-purple }

- Twitter sentiment analysis ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/prob-app1.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/prob-app1.ipynb), [slides](http://www.math.wisc.edu/~roch/mmids/prob-app1.slides.html))
- Kalman filtering ([html](https://nbviewer.jupyter.org/url/www.math.wisc.edu/~roch/mmids/prob-app2.ipynb), [ipynb](http://www.math.wisc.edu/~roch/mmids/prob-app2.ipynb), [slides](http://www.math.wisc.edu/~roch/mmids/prob-app2.slides.html))
- datasets: [twitter-sentiment.csv](http://www.math.wisc.edu/~roch/mmids/twitter-sentiment.csv)

 <br>
